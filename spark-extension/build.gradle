plugins {
    id 'scala'
    id 'com.github.johnrengelman.shadow' version '5.2.0'
    id "me.champeau.gradle.jmh" version "0.5.0"
}

group 'nl.tudelft.nonnenmacher'
version '1.0-SNAPSHOT'

sourceCompatibility = 1.8

repositories {
    mavenCentral()
}

dependencies {
    compile project(':arrow-processor')

    compile "org.scala-lang:scala-library:" + scalaVersion
    compile "org.scala-lang:scala-reflect:" + scalaVersion
    compile "org.scala-lang:scala-compiler:" + scalaVersion

    compile "org.apache.spark:spark-sql_2.12:$sparkVersion"
    compile "org.apache.spark:spark-catalyst_2.12:$sparkVersion"
    compile "org.apache.spark:spark-core_2.12:$sparkVersion"

    //USE JUnit 4 instead because scalatest is not compatible with jUni5
    testCompile 'org.scalatest:scalatest_2.12:3.0.8'
    testImplementation('junit:junit:4.13')
}

def libraryPaths = System.getenv("LD_LIBRARY_PATH")?.split(':')?.toList() ?: []
libraryPaths.addAll([file("${project(':arrow-processor-native').buildDir}/lib/main/debug").absolutePath,
                    "/home/yyonsel/bulk/project/local/lib64",
                    "/home/yyonsel/bulk/project/local/lib",
                    "/usr/local/lib64",
                    "/usr/local/lib"])

test {
    systemProperty "java.library.path", libraryPaths.join(':')
    systemProperty "io.netty.allocator.directMemoryCacheAlignment", "64"
    maxHeapSize = "6G"
}

def metricsFile = "${project.buildDir}/reports/jmh/metrics.csv"
def metricsRawFile = "${project.buildDir}/reports/jmh/metrics-raw.csv"

// JMH Configuration
jmh {
    duplicateClassesStrategy = DuplicatesStrategy.EXCLUDE
    zip64 = true //https://github.com/melix/jmh-gradle-plugin/issues/159#issuecomment-623278956
    jvmArgs = ["-Djava.library.path=${libraryPaths.join(':')}".toString(),
               "-Dproject.root=${project.rootDir}".toString(),
               "-Doutput.metrics=$metricsFile".toString(),
               "-Doutput.metrics.raw=$metricsRawFile".toString(),
               '-Xms6G', '-Xmx6G',
                "-Dio.netty.allocator.directMemoryCacheAlignment=64"]
    humanOutputFile = project.file("${project.buildDir}/reports/jmh/details.txt")
    failOnError = true
}

def jmhTask = project.tasks.findByPath(":$project.name:jmh")

jmhTask.doFirst {
    file(metricsFile).delete()
}

jmhJar {
    mergeServiceFiles()
    archiveName("spark-extension-jmh.jar")
    zip64 = true //https://github.com/melix/jmh-gradle-plugin/issues/159#issuecomment-623278956

}

static String opt(String k, opt) {
    if (opt.hasValue()) {
        return "-$k ${opt.get()}"
    } else ""
}

task generateJmhStartScript {
    group("jmh")
    doLast {
        def options = jmh.resolveArgs()

        def jvmArgs = options.jvmArgs.get().join(" ")
        def jarFile = jmhJar.outputs.files[0].absoluteFile
        def jmhOpts = [opt("o", options.output),
                       opt("rff", options.result),
                       opt("rf", options.resultFormat),
                       opt("foe", options.shouldFailOnError())].join(' ')

        def outputDir = jmhJar.outputs.files[0].parent
        def runBenchmarkScriptFile = file("$outputDir/run_benchmark.sh")
        runBenchmarkScriptFile.text = "rm -f $metricsFile && rm -f $metricsRawFile && java -jar $jvmArgs $jarFile $jmhOpts"
        runBenchmarkScriptFile.setExecutable(true)
    }
}
jmhJar.finalizedBy(generateJmhStartScript)
